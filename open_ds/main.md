2. Признаки:
    - Количественные(возраст, зарплата) - если представляем что значение этого признака может быть произвольным числовым.
    - Категориальные - множество их значений ограничено и на них нельзя задать порядок (область, город, место посадки пассажира Титаника). Но предполагается что множество       значений категориального признака больше двух(> 2) иначе это бинарные признаки.
    - Бинарный - частный случай категориального.

медиана + 2 стандартных отклонения - если превышает - выброс

метод isin - проверяет на вхождение.

3. 
    Классификация и регрессия относятся к методам обучения с учителем.

    - Классификация - множество значений конечно

    - Регрессия - значения могут быть любыми(возраст, зп)

    Критерии информативности - показывают на сколько наш признак хорош для того чтобы по нему разбить нашу выборку на два класса.  

    Чем выше энтропия - тем выше хаос(насколько перемешаны объекты по целевому признаку)

    Information gain - по приросту информации для каждого признака определяем более упорядоченную систему чем на предыдущем шаге.  

    Торможение роста дерева чтобы не начать порождать слишком частные правила, которые работают только для малой группы людей.  

    отложенная выборка - holdout (70% / 30%)

    До разбиения на основную и отложенную выборки необходимо посмотреть на данные и перемешать - чтобы не было такого случая что сначала идут только мужчины и мы тренируем только на них, а в отложенной выборке только женщины.  

    Если вообще данных очень мало(150 человек) - применяется кросс-валидация

    k-fold

    k=3 => 110 101 011

    популярные значения для k = 3, 5, 7, 10

    leave one out - кросс-валидация  

    желательно соблюсти соотношение целевого класса в каждой из подвыборок - стратифицированные методы(stratified) StratifiedkFold

    в настоящее время на практике советуют отщепить 30% исходной выборки для отложенной части, а на оставшейся части провести кросс-валидацию.  

    Переобучение - модель, обученная на своей выборке, будет на ней работать лучше, чем на какой-то другой.  

    гиперпараметры???

    гипотеза компактности - схожие признаки ведут к схожим меткам.  

    Евклидово расстояние.  
    если возраст и зарплата изменяются в разном диапазоне, то в Евклидову метрику они вносят разный вклад.  

    Алгоритмы классификации можно поделить на 3 метода:
     - метрические (метод ближайших соседей)
     - деревья + boosting + RF
     - линейные методы(логистическая регрессия)

    Техника one-hot-encoding, get_dummies

4.  Теория оптимизации
    метод найменьших квадратов
    градиентный спуск
    логистическая регрессия - задача классификации